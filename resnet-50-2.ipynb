{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.python.keras import models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9145533444723251860\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many(list_files):\n",
    "    list_imgs=list(glob.glob(list_files))\n",
    "    imgs=[]\n",
    "    for i in range(len(list_imgs)):\n",
    "        try:\n",
    "            img = image.load_img(list_imgs[i], target_size=(224,224,3))\n",
    "            x = image.img_to_array(img)\n",
    "            imgs.append(x)\n",
    "        except ValueError:\n",
    "            print(\"error reading the following image:\",list_imgs[i])\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_dir(directory):\n",
    "    \n",
    "    covid=read_many(\"{}/COVID/*\".format(directory))\n",
    "    y_covid=[1]*len(covid)\n",
    "    non_covid=read_many(\"{}/COVID/*\".format(directory))\n",
    "    y_non_covid=[0]*len(non_covid)\n",
    "    X=np.concatenate([np.asarray(covid), np.asarray(non_covid)])\n",
    "    Y=np.concatenate([np.asarray(y_covid), np.asarray(y_non_covid)])\n",
    "    return (X, Y) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=load_dir(\"Dataset/Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    conv_base = ResNet50(weights='imagenet',\n",
    "                         #include_top = False,\n",
    "                         #input_shape = (224,224, 3)\n",
    "                        )\n",
    "\n",
    "\n",
    "    # conv_base.summary()\n",
    "    \n",
    "    conv_base.trainable = True\n",
    "    #model=conv_base\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(256, activation = 'relu'))\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6937 - accuracy: 0.3571\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6956 - accuracy: 0.4286\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6890 - accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6836 - accuracy: 0.6429\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6921 - accuracy: 0.4286\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6926 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6815 - accuracy: 0.6429\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6943 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6994 - accuracy: 0.4286\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7005 - accuracy: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b2c25c7f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X/255,y=Y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49341002, 0.5082426 ],\n",
       "       [0.493464  , 0.5083346 ],\n",
       "       [0.49345556, 0.5083247 ],\n",
       "       [0.4934366 , 0.5083368 ],\n",
       "       [0.49342066, 0.5084699 ],\n",
       "       [0.4934574 , 0.5083052 ],\n",
       "       [0.4934563 , 0.5083396 ],\n",
       "       [0.49341002, 0.5082426 ],\n",
       "       [0.493464  , 0.5083346 ],\n",
       "       [0.49345556, 0.5083247 ],\n",
       "       [0.4934366 , 0.5083368 ],\n",
       "       [0.49342066, 0.5084699 ],\n",
       "       [0.4934574 , 0.5083052 ],\n",
       "       [0.4934563 , 0.5083396 ]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
