{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1624304728755,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "zKVy7q3IGkgB"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.python.keras import models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzZHHKErH09V"
   },
   "source": [
    "### Print the device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1624305001335,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "PSSuVbkrGkgI",
    "outputId": "af09cfaa-9128-4729-d2d3-047dbcfe9ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3214499273677409488\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[0], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UINzptJhH5c_"
   },
   "source": [
    "### Get the images of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1624305908282,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "MVyp54N7IJO2"
   },
   "outputs": [],
   "source": [
    "def read_many(path):\n",
    "    \"\"\"\n",
    "    Read all imagens in directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Dataset path of a class (COVID or NON-COVID).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : [ndarray]\n",
    "        List of images.\n",
    "    \"\"\"\n",
    "    # Get the path of all images\n",
    "    list_imgs = list(glob.glob(path))\n",
    "    out = []\n",
    "    \n",
    "    # Load all images of the given paths\n",
    "    for i in range(len(list_imgs)):\n",
    "        # Read the image in shape of (244, 244, 3)\n",
    "        try:\n",
    "            img = image.load_img(list_imgs[i], target_size=(224, 224, 3))\n",
    "            x = image.img_to_array(img)\n",
    "            out.append(x)\n",
    "        # Print error\n",
    "        except ValueError:\n",
    "            print('Error reading the following image:', list_imgs[i])\n",
    "    \n",
    "    # Return the loaded images\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_dir(paths):\n",
    "    \"\"\"\n",
    "    Read images of COVID and NON-COVID cases.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    paths: [str]\n",
    "        Original and augmented dataset paths.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : [ndarray]\n",
    "        List of images.\n",
    "    Y : [str]\n",
    "        Labels of the images (i.e., 0 - NON-COVID; 1 - COVID).\n",
    "    \"\"\"\n",
    "    # Arrays of images of COVID and NON-COVID cases\n",
    "    covid = []\n",
    "    non_covid = []\n",
    "    \n",
    "    # Read images\n",
    "    for path in paths:\n",
    "        # Read images of covid cases\n",
    "        covid.extend(read_many('{}/COVID/*'.format(path)))\n",
    "        # Read images of non-covid cases\n",
    "        non_covid.extend(read_many('{}/NON_COVID/*'.format(path)))\n",
    "    \n",
    "    # Set COVID classes\n",
    "    y_covid = np.asarray([1] * len(covid))\n",
    "    y_non_covid = np.asarray([0] * len(non_covid))\n",
    "    \n",
    "    # Merge the read images\n",
    "    X = np.concatenate([np.array(covid), np.array(non_covid)]) / 255\n",
    "    Y = np.concatenate([np.array(y_covid), np.array(y_non_covid)])\n",
    "    \n",
    "    assert len(X) == len(Y), 'The number of images and the number of classes are different!'\n",
    "    print('Images read:', len(X))\n",
    "    \n",
    "    # Return the read images and their labels\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1624305910664,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "nXfTc39zGkgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images read: 168\n"
     ]
    }
   ],
   "source": [
    "TrainX, TrainY = load_dir(['Dataset/Train', 'Augmented/Train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b337LlciKamR"
   },
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1624306084834,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "jSFyLvWtGkgN"
   },
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    \"\"\"\n",
    "    Return a Convolutional Neural Network (CNN) architecture.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Model\n",
    "        The CNN model architeture.\n",
    "    \"\"\"\n",
    "    # Create a new ResNet50\n",
    "    conv_base = ResNet50(weights='imagenet',\n",
    "                         # include_top = False,\n",
    "                         # input_shape = (224,224, 3)\n",
    "                        )\n",
    "    # conv_base.summary()\n",
    "    # Set the ResNet50 as trainable\n",
    "    conv_base.trainable = True\n",
    "    \n",
    "    # model = conv_base\n",
    "    # Instance of a sequential neural network\n",
    "    model = models.Sequential()\n",
    "    # Add the resnet50 to the sequential CNN\n",
    "    model.add(conv_base)\n",
    "    # Add a flaterns layer\n",
    "    model.add(layers.Flatten())\n",
    "    # Add a droput layer to avoid overfiting\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    # Add relu layer for future classification\n",
    "    model.add(layers.Dense(256, activation = 'relu'))\n",
    "    # Add a final sigmoid layer for binary classification\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    # model.summary()\n",
    "    \n",
    "    # Compile the CNN model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']      # model configuration\n",
    "                 )\n",
    "    \n",
    "    # Return the built CNN model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1624306091169,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "Q8cAtlNIGkgO"
   },
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6MnS3hcKmBO"
   },
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "error",
     "timestamp": 1624306151415,
     "user": {
      "displayName": "Breno Mauricio de Freitas Viana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihbovfudEt4TcKCvVQzlIxS9tXhiHfhQOgWBUP=s64",
      "userId": "09535906535393894999"
     },
     "user_tz": 180
    },
    "id": "LgPbQr1NGkgQ",
    "outputId": "83d1b7ff-0115-4fb7-cef0-0462a8982bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 35s 5s/step - loss: 0.6761 - accuracy: 0.6905\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6294 - accuracy: 0.7857\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.5873 - accuracy: 0.7560\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5639 - accuracy: 0.7560\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5292 - accuracy: 0.8214\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.4994 - accuracy: 0.8214\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.4747 - accuracy: 0.8214\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 34s 6s/step - loss: 0.4519 - accuracy: 0.8155\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.4208 - accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.4036 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff055c6ea00>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=TrainX, y=TrainY, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "resnet-50-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
